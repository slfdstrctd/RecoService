{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debc4873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from IPython.display import display, clear_output\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = pd.read_csv('../data/interactions_processed.csv')\n",
    "users_df = pd.read_csv('../data/users_processed.csv')\n",
    "items_df = pd.read_csv('../data/items_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85049f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbac8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = interactions_df[interactions_df['last_watch_dt'] < '2021-04-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe98dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78342a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_interactions_count_df = interactions_df.groupby(['user_id', 'item_id']).size().groupby(\n",
    "    'user_id').size()\n",
    "print('# users: %d' % len(users_interactions_count_df))\n",
    "users_with_enough_interactions_df = \\\n",
    "    users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['user_id']]\n",
    "print('# users with at least 5 interactions: %d' % len(users_with_enough_interactions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd0d31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# of interactions: %d' % len(interactions_df))\n",
    "interactions_from_selected_users_df = interactions_df.merge(users_with_enough_interactions_df,\n",
    "                                                            how='right',\n",
    "                                                            left_on='user_id',\n",
    "                                                            right_on='user_id')\n",
    "print('# of interactions from users with at least 5 interactions: %d' % len(\n",
    "    interactions_from_selected_users_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46ee003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df43577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_user_preference(x):\n",
    "    return math.log(1 + x, 2)\n",
    "\n",
    "\n",
    "interactions_full_df = interactions_from_selected_users_df \\\n",
    "    .groupby(['user_id', 'item_id'])['watched_pct'].sum() \\\n",
    "    .apply(smooth_user_preference).reset_index()\n",
    "print('# of unique user/item interactions: %d' % len(interactions_full_df))\n",
    "interactions_full_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039e1442",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_train_df, interactions_test_df = train_test_split(interactions_full_df,\n",
    "                                                               stratify=interactions_full_df[\n",
    "                                                                   'user_id'],\n",
    "                                                               test_size=0.20,\n",
    "                                                               random_state=42)\n",
    "\n",
    "print('# interactions on Train set: %d' % len(interactions_train_df))\n",
    "print('# interactions on Test set: %d' % len(interactions_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b38dea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Indexing by personId to speed up the searches during evaluation\n",
    "interactions_full_indexed_df = interactions_full_df.set_index('user_id')\n",
    "interactions_train_indexed_df = interactions_train_df.set_index('user_id')\n",
    "interactions_test_indexed_df = interactions_test_df.set_index('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb9a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_interacted(person_id, interactions_df):\n",
    "    # Get the user's data and merge in the movie information.\n",
    "    interacted_items = interactions_df.loc[person_id]['item_id']\n",
    "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03042d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Top-N accuracy metrics consts\n",
    "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
    "\n",
    "\n",
    "class ModelEvaluator:\n",
    "\n",
    "    def get_not_interacted_items_sample(self, person_id, sample_size, seed=42):\n",
    "        interacted_items = get_items_interacted(person_id, interactions_full_indexed_df)\n",
    "        all_items = set(interactions_full_indexed_df['item_id'])\n",
    "        non_interacted_items = all_items - interacted_items\n",
    "\n",
    "        random.seed(seed)\n",
    "        non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
    "        return set(non_interacted_items_sample)\n",
    "\n",
    "    def _verify_hit_top_n(self, item_id, recommended_items, topn):\n",
    "        try:\n",
    "            index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
    "        except:\n",
    "            index = -1\n",
    "        hit = int(index in range(0, topn))\n",
    "        return hit, index\n",
    "\n",
    "    def evaluate_model_for_user(self, model, person_id):\n",
    "        #Getting the items in test set\n",
    "        interacted_values_testset = interactions_test_indexed_df.loc[person_id]\n",
    "        if type(interacted_values_testset['item_id']) == pd.Series:\n",
    "            person_interacted_items_testset = set(interacted_values_testset['item_id'])\n",
    "        else:\n",
    "            person_interacted_items_testset = {int(interacted_values_testset['item_id'])}\n",
    "        interacted_items_count_testset = len(person_interacted_items_testset)\n",
    "\n",
    "        #Getting a ranked recommendation list from a model for a given user\n",
    "        person_recs_df = model.recommend_items(person_id,\n",
    "                                               items_to_ignore=get_items_interacted(person_id,\n",
    "                                                                                    interactions_train_indexed_df),\n",
    "                                               topn=10000000000)\n",
    "\n",
    "        hits_at_5_count = 0\n",
    "        hits_at_10_count = 0\n",
    "        #For each item the user has interacted in test set\n",
    "        for item_id in person_interacted_items_testset:\n",
    "            #Getting a random sample (100) items the user has not interacted \n",
    "            #(to represent items that are assumed to be no relevant to the user)\n",
    "            non_interacted_items_sample = self.get_not_interacted_items_sample(person_id,\n",
    "                                                                               sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS,\n",
    "                                                                               seed=item_id % (\n",
    "                                                                                   2 ** 32))\n",
    "\n",
    "            #Combining the current interacted item with the 100 random items\n",
    "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
    "\n",
    "            #Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
    "            valid_recs_df = person_recs_df[person_recs_df['item_id'].isin(items_to_filter_recs)]\n",
    "            valid_recs = valid_recs_df['item_id'].values\n",
    "            #Verifying if the current interacted item is among the Top-N recommended items\n",
    "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
    "            hits_at_5_count += hit_at_5\n",
    "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
    "            hits_at_10_count += hit_at_10\n",
    "\n",
    "        #Recall is the rate of the interacted items that are ranked among the Top-N recommended items, \n",
    "        #when mixed with a set of non-relevant items\n",
    "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
    "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
    "\n",
    "        person_metrics = {'hits@5_count': hits_at_5_count,\n",
    "                          'hits@10_count': hits_at_10_count,\n",
    "                          'interacted_count': interacted_items_count_testset,\n",
    "                          'recall@5': recall_at_5,\n",
    "                          'recall@10': recall_at_10}\n",
    "        return person_metrics\n",
    "\n",
    "    def evaluate_model(self, model):\n",
    "        #print('Running evaluation for users')\n",
    "        people_metrics = []\n",
    "        for idx, person_id in enumerate(\n",
    "            tqdm(list(interactions_test_indexed_df.index.unique().values))):\n",
    "            #if idx % 100 == 0 and idx > 0:\n",
    "            #    print('%d users processed' % idx)\n",
    "            person_metrics = self.evaluate_model_for_user(model, person_id)\n",
    "            person_metrics['user_id'] = person_id\n",
    "            people_metrics.append(person_metrics)\n",
    "        print('%d users processed' % idx)\n",
    "\n",
    "        detailed_results_df = pd.DataFrame(people_metrics) \\\n",
    "            .sort_values('interacted_count', ascending=False)\n",
    "\n",
    "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(\n",
    "            detailed_results_df['interacted_count'].sum())\n",
    "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(\n",
    "            detailed_results_df['interacted_count'].sum())\n",
    "\n",
    "        global_metrics = {'modelName': model.get_model_name(),\n",
    "                          'recall@5': global_recall_at_5,\n",
    "                          'recall@10': global_recall_at_10}\n",
    "        return global_metrics, detailed_results_df\n",
    "\n",
    "\n",
    "model_evaluator = ModelEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c56b58f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9039ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Constants\n",
    "SEED = 42  # random seed for reproducibility\n",
    "LR = 1e-3  # learning rate, controls the speed of the training\n",
    "WEIGHT_DECAY = 0.01  # lambda for L2 reg. ()\n",
    "NUM_EPOCHS = 200  # num training epochs (how many times each instance will be processed)\n",
    "GAMMA = 0.9995  # learning rate scheduler parameter\n",
    "BATCH_SIZE = 3000  # training batch size\n",
    "EVAL_BATCH_SIZE = 3000  # evaluation batch size.\n",
    "DEVICE = 'cuda'  #'cuda' # device to make the calculations on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47f52ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = interactions_train_df.append(interactions_test_indexed_df.reset_index())\n",
    "total_df['user_id'], users_keys = total_df.user_id.factorize()\n",
    "total_df['item_id'], items_keys = total_df.item_id.factorize()\n",
    "\n",
    "train_encoded = total_df.iloc[:len(interactions_train_df)].values\n",
    "test_encoded = total_df.iloc[len(interactions_train_df):].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e538cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "shape = [int(total_df['user_id'].max() + 1), int(total_df['item_id'].max() + 1)]\n",
    "X_train = csr_matrix((train_encoded[:, 2], (train_encoded[:, 0], train_encoded[:, 1])),\n",
    "                     shape=shape).toarray()\n",
    "X_test = csr_matrix((test_encoded[:, 2], (test_encoded[:, 0], test_encoded[:, 1])),\n",
    "                    shape=shape).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cc28b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the DataObject, which must return an element (features vector x and target value y)\n",
    "# for a given idx. This class must also have a length atribute\n",
    "class UserOrientedDataset(Dataset):\n",
    "    def __init__(self, X):\n",
    "        super().__init__()  # to initialize the parent class\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.len = len(X)\n",
    "\n",
    "    def __len__(self):  # We use __func__ for implementing in-built python functions\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee1dfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize DataLoaders - objects, which sample instances from DataObject-s\n",
    "train_dl = DataLoader(\n",
    "    UserOrientedDataset(X_train),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    UserOrientedDataset(X_test),\n",
    "    batch_size=EVAL_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "dls = {'train': train_dl, 'test': test_dl}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27054192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Model(nn.Module):\n",
    "#     def __init__(self, in_and_out_features = 8287):\n",
    "#         super().__init__()\n",
    "#         self.in_and_out_features = in_and_out_features\n",
    "#         self.hidden_size = 500\n",
    "# \n",
    "#         self.sequential = nn.Sequential( # NN architecure, where the modules modify the data sequentially\n",
    "#             nn.Linear(in_and_out_features, self.hidden_size),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5),  \n",
    "#             nn.Linear(self.hidden_size, self.hidden_size),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm1d(self.hidden_size), \n",
    "#             nn.Linear(self.hidden_size, self.hidden_size),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(self.hidden_size, in_and_out_features),\n",
    "#             nn.Softmax(dim=1)\n",
    "#         )\n",
    "# \n",
    "#     def forward(self, x): # In the forward function, you define how your model runs, from input to output \n",
    "#         x = self.sequential(x)\n",
    "#         return xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c15b27cd43728bb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T01:10:52.241343400Z",
     "start_time": "2023-12-13T01:10:52.225564900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_and_out_features=8287, hidden_size=500):\n",
    "        super(Model, self).__init__()\n",
    "        self.in_and_out_features = in_and_out_features\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_and_out_features, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, hidden_size),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, in_and_out_features),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2c95f9af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T01:10:53.533380600Z",
     "start_time": "2023-12-13T01:10:53.399404400Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)  # Fix random seed to have reproducible weights of model layers\n",
    "\n",
    "model = Model()\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Initialize GD method, which will update the weights of the model\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "# Initialize learning rate scheduler, which will decrease LR according to some rule\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=GAMMA)\n",
    "\n",
    "\n",
    "def rmse_for_sparse(x_pred, x_true):\n",
    "    mask = (x_true > 0)\n",
    "    sq_diff = (x_pred * mask - x_true) ** 2\n",
    "    mse = sq_diff.sum() / mask.sum()\n",
    "    return mse ** (1 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e9cdaf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Test RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.315794</td>\n",
       "      <td>2.250791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.087116</td>\n",
       "      <td>2.186675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.974711</td>\n",
       "      <td>2.124670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.899748</td>\n",
       "      <td>2.022762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.844253</td>\n",
       "      <td>1.986536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>0.980888</td>\n",
       "      <td>1.452995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>0.980011</td>\n",
       "      <td>1.449011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>0.977394</td>\n",
       "      <td>1.449030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>0.977802</td>\n",
       "      <td>1.440107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>0.976070</td>\n",
       "      <td>1.444731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Epoch  Train RMSE  Test RMSE\n",
       "0        0    2.315794   2.250791\n",
       "1        1    2.087116   2.186675\n",
       "2        2    1.974711   2.124670\n",
       "3        3    1.899748   2.022762\n",
       "4        4    1.844253   1.986536\n",
       "..     ...         ...        ...\n",
       "195    195    0.980888   1.452995\n",
       "196    196    0.980011   1.449011\n",
       "197    197    0.977394   1.449030\n",
       "198    198    0.977802   1.440107\n",
       "199    199    0.976070   1.444731\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:50<00:00,  1.18it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Training loop\n",
    "metrics_dict = {\n",
    "    \"Epoch\": [],\n",
    "    \"Train RMSE\": [],\n",
    "    \"Test RMSE\": [],\n",
    "}\n",
    "\n",
    "# Train loop\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    metrics_dict[\"Epoch\"].append(epoch)\n",
    "    for stage in ['train', 'test']:\n",
    "        with torch.set_grad_enabled(\n",
    "            stage == 'train'):  # Whether to start building a graph for a backward pass\n",
    "            if stage == 'train':\n",
    "                model.train()  # Enable some \"special\" layers (will speak about later)\n",
    "            else:\n",
    "                model.eval()  # Disable some \"special\" layers (will speak about later)\n",
    "\n",
    "            loss_at_stage = 0\n",
    "            for batch in dls[stage]:\n",
    "                batch = batch.to(DEVICE)\n",
    "                x_pred = model(batch)  # forward pass: model(x_batch) -> calls forward()\n",
    "                loss = rmse_for_sparse(x_pred, batch)  # ¡Important! y_pred is always the first arg\n",
    "                if stage == \"train\":\n",
    "                    loss.backward()  # Calculate the gradients of all the parameters wrt loss\n",
    "                    optimizer.step()  # Update the parameters\n",
    "                    scheduler.step()\n",
    "                    optimizer.zero_grad()  # Zero the saved gradient\n",
    "                loss_at_stage += loss.item() * len(batch)\n",
    "            rmse_at_stage = (loss_at_stage / len(dls[stage].dataset)) ** (1 / 2)\n",
    "            metrics_dict[f\"{stage.title()} RMSE\"].append(rmse_at_stage)\n",
    "\n",
    "    if (epoch == NUM_EPOCHS - 1) or epoch % 10 == 9:\n",
    "        clear_output(wait=True)\n",
    "        display(pd.DataFrame(metrics_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a9bf9546",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T01:13:50.281470900Z",
     "start_time": "2023-12-13T01:13:49.815835300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.9721, 6.9679, 1.8702,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [2.0620, 3.1590, 0.0702,  ..., 0.0229, 0.0000, 0.0956],\n",
       "        [4.1277, 4.3343, 3.2598,  ..., 0.0000, 0.1393, 0.0317],\n",
       "        ...,\n",
       "        [2.3818, 3.3578, 0.2149,  ..., 0.0000, 0.0000, 0.1067],\n",
       "        [2.6024, 3.5653, 3.6185,  ..., 0.0000, 0.7004, 0.3730],\n",
       "        [3.8981, 4.7623, 2.3583,  ..., 0.0000, 0.1025, 0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_pred = model(torch.Tensor(X_test).to(DEVICE))\n",
    "X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3bca32fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T01:29:28.305384900Z",
     "start_time": "2023-12-13T01:29:28.050942300Z"
    }
   },
   "outputs": [],
   "source": [
    "class AERecommender:\n",
    "    MODEL_NAME = 'Autoencoder'\n",
    "\n",
    "    def __init__(self, X_preds, X_train_and_val, X_test):\n",
    "        self.X_preds = X_preds.cpu().detach().numpy()\n",
    "        self.X_train_and_val = X_train_and_val\n",
    "        self.X_test = X_test\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "\n",
    "    def recommend_items(self, user_id, items_to_select_idx, topn=10, verbose=False):\n",
    "        user_preds = self.X_preds[user_id][items_to_select_idx]\n",
    "        items_idx = items_to_select_idx[np.argsort(-user_preds)[:topn]]\n",
    "        return items_idx\n",
    "\n",
    "    def recommend(self, user_id, topn=10):\n",
    "        non_interacted_items = np.argwhere(self.X_test[user_id] == 0).ravel()\n",
    "\n",
    "        if len(non_interacted_items) == 0:\n",
    "            return []\n",
    "        user_preds = self.X_preds[user_id][non_interacted_items]\n",
    "        items_idx = non_interacted_items[np.argsort(-user_preds)[:topn]]\n",
    "\n",
    "        return list(items_idx)\n",
    "\n",
    "    def evaluate(self, size=100):\n",
    "        X_total = self.X_train_and_val + self.X_test\n",
    "\n",
    "        true_5 = []\n",
    "        true_10 = []\n",
    "\n",
    "        for user_id in range(len(X_test)):\n",
    "            non_zero = np.argwhere(self.X_test[user_id] > 0).ravel()\n",
    "            all_nonzero = np.argwhere(X_total[user_id] > 0).ravel()\n",
    "            select_from = np.setdiff1d(np.arange(X_total.shape[1]), all_nonzero)\n",
    "\n",
    "            for non_zero_idx in non_zero:\n",
    "                random_non_interacted_100_items = np.random.choice(select_from, size=20,\n",
    "                                                                   replace=False)\n",
    "                preds = self.recommend_items(user_id, np.append(random_non_interacted_100_items,\n",
    "                                                                non_zero_idx), topn=10)\n",
    "                true_5.append(non_zero_idx in preds[:5])\n",
    "                true_10.append(non_zero_idx in preds)\n",
    "\n",
    "        return {\"recall@5\": np.mean(true_5), \"recall@10\": np.mean(true_10)}\n",
    "\n",
    "\n",
    "ae_recommender_model = AERecommender(X_pred, X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4d846334",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T01:29:34.119814600Z",
     "start_time": "2023-12-13T01:29:28.863972500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall@5': 0.6073607634543179, 'recall@10': 0.8087453066332916}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_global_metrics = ae_recommender_model.evaluate()\n",
    "ae_global_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b3060c0037afbcdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T01:29:43.595245900Z",
     "start_time": "2023-12-13T01:29:43.580224500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7347, 6278, 3463, 3270, 3310, 7430, 2669, 3955, 4539, 3821]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_recommender_model.recommend(user_id=1, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5483120393dd2b22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T01:31:57.840537Z",
     "start_time": "2023-12-13T01:31:51.250354100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recs = {}\n",
    "\n",
    "for i, user_id in enumerate(interactions_full_indexed_df.index.unique()):\n",
    "    user_recs = ae_recommender_model.recommend(i, 10)\n",
    "    recs.update({user_id: user_recs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6609bc5cfca017c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T01:32:04.801692300Z",
     "start_time": "2023-12-13T01:32:04.531124500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../saved_models/ae_offline.pkl', 'wb') as f:\n",
    "    pickle.dump(recs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0762e13f80b7c3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
